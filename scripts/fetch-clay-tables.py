#!/usr/bin/env python3
"""
Clay Tables Fetcher
Fetches table schemas from specific workspaces and generates documentation.
"""

import os
import sys
import json
import requests
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Base directory
BASE_DIR = Path(__file__).parent.parent
CONFIG_FILE = BASE_DIR / "config" / "integration-filters.json"
OUTPUT_FILE = BASE_DIR / "business-knowledge" / "api-integrations" / "clay" / "tables" / "table-schemas.md"

# Clay API endpoints
CLAY_API_BASE = "https://api.clay.com/v1"


def load_config():
    """Load integration filters configuration"""
    with open(CONFIG_FILE, 'r') as f:
        return json.load(f)


def get_clay_headers():
    """Get headers for Clay API requests"""
    api_key = os.getenv('CLAY_API_KEY')
    if not api_key:
        print("‚ùå Error: CLAY_API_KEY not found in .env file")
        sys.exit(1)

    return {
        'Authorization': f'Bearer {api_key}',
        'Content-Type': 'application/json'
    }


def fetch_tables(config):
    """Fetch tables from Clay API"""
    print("üîÑ Fetching Clay tables...")

    headers = get_clay_headers()
    workspace_id = config['clay'].get('workspace_id')

    # Fetch tables
    url = f"{CLAY_API_BASE}/tables"
    if workspace_id:
        url += f"?workspaceId={workspace_id}"

    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        tables = response.json().get('tables', [])

        print(f"‚úÖ Found {len(tables)} total tables")
        return tables

    except requests.exceptions.RequestException as e:
        print(f"‚ùå Error fetching tables: {e}")
        print(f"   If Clay API structure differs, check documentation at https://clay.com/docs")
        return []


def filter_tables(tables, config):
    """Filter tables based on configuration"""
    filters = config['clay']['filters']
    include_tables = filters.get('include_tables', [])
    exclude_tables = filters.get('exclude_tables', [])
    include_tags = filters.get('include_tags', [])

    filtered = []

    for table in tables:
        name = table.get('name', '')
        tags = table.get('tags', [])

        # Skip if in exclude list
        if exclude_tables and any(exclude in name for exclude in exclude_tables):
            continue

        # Include if in include list or has include tags
        if include_tables and any(include in name for include in include_tables):
            filtered.append(table)
        elif include_tags and any(tag in include_tags for tag in tags):
            filtered.append(table)
        elif not include_tables and not include_tags:
            # If no include filters, include everything not excluded
            filtered.append(table)

    print(f"‚úÖ Filtered to {len(filtered)} tables matching your criteria")
    return filtered


def generate_markdown(tables, config):
    """Generate markdown documentation"""

    md = f"""# Clay Tables Documentation

*Last Updated: {datetime.now().strftime('%Y-%m-%d')}*
*Auto-generated by fetch-clay-tables.py*

## Overview

This document catalogs all Clay tables for YNA Agentic, filtered by workspace and configuration.

**Total Tables**: {len(tables)}
**Workspace**: {config['clay'].get('workspace_name', 'Not specified')}

---

## Configuration

**Workspace ID**: {config['clay'].get('workspace_id', 'Not set')}
**Included Tables**: {', '.join(config['clay']['filters'].get('include_tables', ['All']))}
**Excluded Tables**: {', '.join(config['clay']['filters'].get('exclude_tables', ['None']))}

---

## Active Tables Summary

| Table Name | Purpose | Record Count | Enrichment Providers | Output | Created |
|-----------|---------|--------------|---------------------|--------|---------|
"""

    for table in tables:
        name = table.get('name', 'Unnamed')
        description = table.get('description', 'No description')
        record_count = table.get('recordCount', 0)
        # Note: Actual enrichment providers would be fetched from table details
        providers = ', '.join(table.get('enrichmentProviders', ['TBD']))
        output = table.get('outputDestination', 'TBD')
        created = table.get('createdAt', 'Unknown')

        md += f"| {name} | {description} | {record_count} | {providers} | {output} | {created} |\n"

    md += "\n---\n\n## Detailed Table Documentation\n\n"

    # Add detailed section for each table
    for table in tables:
        name = table.get('name', 'Unnamed')
        table_id = table.get('id', 'N/A')
        description = table.get('description', 'No description provided')
        created = table.get('createdAt', 'Unknown')
        record_count = table.get('recordCount', 0)

        md += f"""### Table: {name}

**Table ID**: `{table_id}`
**Purpose**: {description}
**Created**: {created}
**Record Count**: {record_count}

#### Input Fields
*To be documented when table details are fetched*

#### Enrichment Waterfall
*Document enrichment providers and sequence*
1. Provider 1: [What it enriches] - [Credits per use]
2. Provider 2: [Fallback] - [Credits per use]

#### Output Fields
*Document output schema*

#### Output Destination
**Platform**: Airtable (typically)
**Base**: [Base name]
**Table**: [Table name]
**Sync Mode**: Real-time

#### Credit Usage
**Estimated Credits per Record**: TBD
**Monthly Usage**: TBD

#### Notes
- [Add any special configuration or notes]

---

"""

    # Add enrichment providers summary
    md += """## Enrichment Provider Usage

| Provider | Purpose | Credits/Use | Tables Using |
|----------|---------|-------------|--------------|
| Clearbit | Company & contact data | 1-5 | TBD |
| Hunter | Email finder & verification | 1 | TBD |
| LinkedIn | Professional profiles | 2-3 | TBD |
| Crunchbase | Company funding data | 2 | TBD |
| BuiltWith | Tech stack detection | 1 | TBD |

*Update this table based on your actual usage*

---

## Credit Management

**Monthly Allocation**: {config['clay'].get('monthly_credits', 100)} credits
**Current Usage**: Check Clay dashboard
**Alert Threshold**: 80% usage

### Credit Optimization Tips
1. Use enrichment waterfalls (try cheap providers first)
2. Cache results in Airtable to avoid re-enrichment
3. Only enrich qualified leads
4. Use filters to skip low-value records
5. Monitor credit usage weekly

---

## Common Table Patterns

### Lead Enrichment Table
- **Input**: Email address
- **Enrichment**: Clearbit ‚Üí Hunter ‚Üí LinkedIn
- **Output**: Airtable Leads table
- **Use Case**: Enrich form submissions

### Company Research Table
- **Input**: Company domain
- **Enrichment**: Clearbit ‚Üí Crunchbase ‚Üí BuiltWith
- **Output**: Airtable Companies table
- **Use Case**: Account-based marketing research

### Contact Finder Table
- **Input**: Company name + role
- **Enrichment**: LinkedIn ‚Üí Hunter (email verification)
- **Output**: Airtable Contacts table
- **Use Case**: Find decision makers

---

## Maintenance

**Update Frequency**: Run `python scripts/fetch-clay-tables.py` daily

**Manual Documentation**: Add enrichment details and notes to each table section above.

---

*To update this file, run: `python scripts/fetch-clay-tables.py`*
"""

    return md


def main():
    """Main execution"""
    print("=" * 60)
    print("Clay Tables Fetcher")
    print("=" * 60)

    # Load configuration
    config = load_config()

    if not config['clay']['enabled']:
        print("‚ö†Ô∏è  Clay integration is disabled in config")
        sys.exit(0)

    # Fetch tables
    tables = fetch_tables(config)

    if not tables:
        print("‚ö†Ô∏è  No tables found")
        sys.exit(0)

    # Filter tables
    filtered_tables = filter_tables(tables, config)

    if not filtered_tables:
        print("‚ö†Ô∏è  No tables match your filters")
        print("   Check config/integration-filters.json")
        sys.exit(0)

    # Generate documentation
    markdown = generate_markdown(filtered_tables, config)

    # Write to file
    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)
    with open(OUTPUT_FILE, 'w') as f:
        f.write(markdown)

    print(f"\n‚úÖ Documentation generated: {OUTPUT_FILE}")
    print(f"   Total tables documented: {len(filtered_tables)}")

    # Save JSON backup
    json_file = OUTPUT_FILE.parent / "tables-data.json"
    with open(json_file, 'w') as f:
        json.dump(filtered_tables, f, indent=2)

    print(f"‚úÖ JSON backup saved: {json_file}")
    print("\n" + "=" * 60)


if __name__ == "__main__":
    main()
